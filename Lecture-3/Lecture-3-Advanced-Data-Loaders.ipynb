{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3 - Advanced Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save DataLoader to Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to normalized Tensors \n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "train_dataset = datasets.MNIST('../Datasets/', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST('../Datasets/', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=len(train_dataset))\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call next on the iterator to get all data.\n",
    "# .numpy() call can convert the tensors to numpy.\n",
    "train_dataset_array = next(iter(train_loader))[0].numpy()\n",
    "train_dataset_array_labels = next(iter(train_loader))[1].numpy()\n",
    "\n",
    "test_dataset_array = next(iter(test_loader))[0].numpy()\n",
    "test_dataset_array_labels = next(iter(test_loader))[1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_array_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_array_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Numpy array to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('MNIST_train.npy', 'wb') as f:\n",
    "    np.save(f, train_dataset_array)\n",
    "    np.save(f, train_dataset_array_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('MNIST_test.npy', 'wb') as f:\n",
    "    np.save(f, test_dataset_array)\n",
    "    np.save(f, test_dataset_array_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the saved Numpy arrays to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('MNIST_train.npy', 'rb') as f:\n",
    "    train_X = np.load(f)\n",
    "    train_Y = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('MNIST_test.npy', 'rb') as f:\n",
    "    test_X = np.load(f)\n",
    "    test_Y = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 64\n",
    "N_test = 256\n",
    "\n",
    "t_mnist_assn_1a_train_X = torch.Tensor(train_X)\n",
    "t_mnist_assn_1a_train_Y = torch.Tensor(train_Y).type(torch.LongTensor)\n",
    "t_mnist_assn_1a_test_X = torch.Tensor(test_X)\n",
    "t_mnist_assn_1a_test_Y = torch.Tensor(test_Y).type(torch.LongTensor)\n",
    "\n",
    "train_data = TensorDataset(t_mnist_assn_1a_train_X, t_mnist_assn_1a_train_Y)\n",
    "train_loader = DataLoader(train_data, batch_size=N_train, shuffle=True)\n",
    "\n",
    "test_data = TensorDataset(t_mnist_assn_1a_test_X, t_mnist_assn_1a_test_Y)\n",
    "test_loader = DataLoader(test_data, batch_size=N_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotate Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_tensor(_in_tensor, plot=True):\n",
    "    \"\"\"\n",
    "    From: https://github.com/arundasan91/IS7033/tree/master/CNN_invariance\n",
    "    \"\"\"\n",
    "    in_tensor = _in_tensor.clone()\n",
    "    # Add one more channel to the beginning. Tensor shape = 1,1,28,28\n",
    "    in_tensor.unsqueeze_(0)\n",
    "    # Convert to Pytorch variable\n",
    "    in_tensor = Variable(in_tensor, requires_grad=True)\n",
    "    \n",
    "    in_tensor_90 = in_tensor.transpose(2, 3).flip(3)\n",
    "    in_tensor_180 = in_tensor.flip(2).flip(3)\n",
    "    in_tensor_270 = in_tensor.transpose(2, 3).flip(2)\n",
    "    \n",
    "    if plot:\n",
    "        plt.figure(1)\n",
    "        plt.subplot(221)\n",
    "        plt.gca().set_title('0 degree')\n",
    "        plt.imshow(in_tensor[0][0].cpu().detach().clone(), cmap='gray')\n",
    "        plt.subplot(222)\n",
    "        plt.gca().set_title('+90 degree')\n",
    "        plt.imshow(in_tensor_90[0][0].cpu().detach().clone(), cmap='gray')\n",
    "        plt.subplot(223)\n",
    "        plt.gca().set_title('+270 degree')\n",
    "        plt.imshow(in_tensor_270[0][0].cpu().detach().clone(), cmap='gray')\n",
    "        plt.subplot(224)\n",
    "        plt.gca().set_title('+180 degree')\n",
    "        plt.imshow(in_tensor_180[0][0].cpu().detach().clone(), cmap='gray')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return(in_tensor, in_tensor_90, in_tensor_180, in_tensor_270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subset = enumerate(test_loader)\n",
    "batch_idx, (one_batch_of_test_subset_x, one_batch_of_test_subset_y) = next(test_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number, number_90, number_180, number_270 = rotate_tensor(one_batch_of_test_subset_x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Rotation Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRotation(object):\n",
    "    \"\"\"Rotate image by a fixed angle which is ready for tranform.Compose()\n",
    "    From: https://github.com/arundasan91/IS7033/tree/master/CNN_invariance\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, degrees, resample=False, expand=False, center=None):\n",
    "        self.degrees = degrees\n",
    "        self.resample = resample\n",
    "        self.expand = expand\n",
    "        self.center = center\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \n",
    "        return transforms.ToTensor()(\n",
    "            transforms.functional.rotate(\n",
    "                transforms.ToPILImage()(img), \n",
    "                self.degrees, self.resample, self.expand, self.center))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(13)\n",
    "\n",
    "N_train = 64\n",
    "N_test = 256\n",
    "\n",
    "rotation = 45 # Specifies the rotation of images.\n",
    "\n",
    "# Define the train and test loader\n",
    "# Here we are adding our CustomRotation function to the transformations\n",
    "train_loader_rot = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../Datasets/', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       CustomRotation(rotation),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=N_train, shuffle=True)\n",
    "\n",
    "test_loader_rot = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../Datasets/', train=False, \n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       CustomRotation(rotation),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=N_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subset_rot = enumerate(test_loader_rot)\n",
    "batch_idx, (one_batch_of_test_subset_x_rot, one_batch_of_test_subset_y_rot) = next(test_subset_rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(one_batch_of_test_subset_x_rot[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(one_batch_of_test_subset_y_rot[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on rotated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.NLLLoss() # also called criterion sometimes.\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
    "start = time.time()\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "for EPOCH in range(NUM_EPOCHS):\n",
    "    running_loss = 0\n",
    "    for images, labels in train_loader_rot:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = loss_fn(output, labels)\n",
    "        \n",
    "        #This is where the model learns by backpropagating\n",
    "        loss.backward()\n",
    "        \n",
    "        #And optimizes its weights here\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(EPOCH, running_loss/len(train_loader)))\n",
    "        \n",
    "print(\"\\nTraining Time (in minutes) =\",(time.time()-start)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on normal images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_count, all_count = 0, 0\n",
    "for images,labels in test_loader:\n",
    "    for i in range(len(labels)):\n",
    "        img = images[i].view(1, 784)\n",
    "        # Turn off gradients to speed up this part\n",
    "        with torch.no_grad():\n",
    "            logps = model(img)\n",
    "\n",
    "        # Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "        ps = torch.exp(logps)\n",
    "        probab = list(ps.numpy()[0])\n",
    "        pred_label = probab.index(max(probab))\n",
    "        true_label = labels.numpy()[i]\n",
    "        if(true_label == pred_label):\n",
    "            correct_count += 1\n",
    "        all_count += 1\n",
    "\n",
    "print(\"Number Of Images Tested =\", all_count)\n",
    "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
