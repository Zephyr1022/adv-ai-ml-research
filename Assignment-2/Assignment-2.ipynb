{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment has two sections:\n",
    " 1. Visualize the 2nd Convolution layer after maxpooling operation. Note that you have to apply maxpooling operation to the conv1 activations to reduce the shape of the activations. After you complete the program, you should add one page discussion and conclusion regarding what you found after visualizing the activations.\n",
    " 2. Extract the embeddings (fc2 layer) of the CNN models for first two number 6's and number 7's from the test loader (code in another notebook). You will have a total of 4 embeddings now, two each for numbers 6 and 7. Now, find the inter and intra class distance (MSE and cross-entropy) of the embeddings. After you complete the program, you should add one page discussion and conclusion regarding what you found after studying the distance between the embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](model.png \"Architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import itertools\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "flatten = itertools.chain.from_iterable\n",
    "\n",
    "# Some helper functions\n",
    "\n",
    "def plot_loss(loss_as_list):\n",
    "    \"\"\"\n",
    "    Plot the loss curve from a list of loss terms.\n",
    "    \"\"\"\n",
    "    plt.plot(loss_as_list, 'k')\n",
    "    _ = plt.title(\"Loss Curve\")\n",
    "    _ = plt.xlabel(\"Epochs\")\n",
    "    _ = plt.ylabel(\"Loss\")\n",
    "    \n",
    "def get_classification_results(model, loader):\n",
    "    \"\"\"\n",
    "    Print the accuracy of a trained model.\n",
    "    Loss: Cross Entropy\n",
    "    \"\"\"\n",
    "    correct, total = 0, 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    for xs, ts in test_loader:\n",
    "        xs = xs.view(-1, 784) # flatten the image\n",
    "        zs = model(xs) # do forward pass\n",
    "        pred = zs.max(1, keepdim=True)[1] # get the index of the max logit\n",
    "        correct += pred.eq(ts.view_as(pred)).sum().item() # count equal values\n",
    "        total += int(ts.shape[0]) # get total values\n",
    "\n",
    "        predictions.append(pred)\n",
    "        true_labels.append(ts)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    conf_matrix = confusion_matrix(list(flatten(true_labels)), list(flatten(predictions)))\n",
    "    cl_report = classification_report(list(flatten(true_labels)), list(flatten(predictions)), digits=4)\n",
    "\n",
    "    print(cl_report)\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load original MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(13)\n",
    "\n",
    "N_train = 64\n",
    "N_test = 256\n",
    "\n",
    "# We will use torch.utils.data.DataLoader to wrap our dataset.\n",
    "# This provides easier batching, GPU support, etc.\n",
    "# Calling torchvision.datasets.MNIST() will download and format the MNIST\n",
    "# dataset with the transforms we specify. Here, in the transforms we first convert\n",
    "# the image to PyTorch tensor, and then normalize the image based on a given mean\n",
    "# and standard deviation. Normalizing the image does: image = (image - mean) / std.\n",
    "# We shuffle the data as well by defining shuffle=True.\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('../Datasets/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=N_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('../Datasets/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=N_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
